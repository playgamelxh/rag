## Data Chunking
#### 一、核心原理与技术目标
Data Chunking是将原始文档分割为语义独立文本块的过程，其本质是在‌信息完整性‌与‌计算效率‌间寻求平衡‌ 。

理想分块需满足：
* 语义自洽性‌：每个块包含完整逻辑单元（如概念定义、事件描述）
* ‌检索适配性‌：块大小匹配向量模型输入限制（通常100-500 tokens）
* 上下文延续性‌：关键关联信息不因分割丢失‌
*
典型反例：将技术文档的「配置步骤」与「错误解决方案」切分到不同块，导致检索结果缺乏操作上下文‌

#### 二、主流分块策略及适用场景
* 固定窗口分块，按固定字符数/词数切割（如每块256 tokens），语义割裂→采用10%-15%重叠缓冲‌，适用标准化文档（新闻/公告）‌
* 语义感知分块，基于标点/段落/HTML标签分割，规则预定义成本高→结合NLP断句模型‌，适用技术手册/论文‌
* ‌滑动窗口分块，相邻块保留重叠区（窗口滑动步长<块大小），存储冗余→动态调整重叠比例‌，适用连贯长文本（小说/报告）‌
* ‌递归分层分块，先按章节分割，再对长段落二次分块，实现复杂→使用LangChain等工具链‌，适用书籍/研究报告‌
* 内容驱动分块，按内容类型差异化切割（文本/表格/代码），需布局识别技术支撑‌，适用混合格式文档（产品说明书）‌

#### 三、前沿优化技术
* 动态分块引擎
    1. Meta-Chunking‌：训练轻量模型预测最优分块参数（如金融报告需300±50 tokens）‌
    2. Late Chunking‌：延迟分块至检索阶段，根据查询动态调整分块粒度‌
* 语义边界检测增强
    1. 使用句嵌入模型（如bge-M3）计算相邻文本相似度，在向量距离骤增点分割‌
    2. 注入结构感知：识别标题层级/Markdown标签，优先在##级标题处分块‌
* 多模态分块
    1. 图文联合分块：将图片描述与邻近文本合并为多模态块‌
    2. 表格特殊处理：保持表格结构完整性，禁止跨表切割‌

#### 四、关键性能指标与评测
| 评估维度     | 量化指标                  | 优化目标              | 工具链          |
|--------------|--------------------------|---------------------|---------------|
| 检索质量     | Hit@5（前5召回块的相关性） | >0.85        | LlamaIndex Eval |
| 语义完整性   | Chunk Coherence Score    | 人工评估得分>4/5 | 专家标注集     |
| 系统效率     | 单文档分块耗时            | <2秒（100页PDF）‌ | cProfile监测  |


#### 五、实践建议与避坑指南
1. ‌分步调优流程
```azure
graph LR
A[分析文档结构] --> B[选择基础策略]
B --> C[小样本测试]
C --> D{评估召回率}
D -->|达标| E[生产部署]
D -->|未达标| F[调整重叠率/边界规则]
```
2. 高频陷阱应对
    * ‌表格断裂‌→ 使用Unstructured.io等库识别表格区域‌
    * 代码碎片化‌→ 按函数/类定义分块，保留import上下文‌
    * 跨页信息割裂‌→ PDF解析时启用跨页内容合并‌

#### 六、工具链推荐
1. 开源框架：LangChain RecursiveCharacterTextSplitter、LlamaIndex SemanticSplitter
2. 云服务：Azure AI Document Intelligence（布局分析）‌
3. 前沿方案：Jina AI jina-seg（自适应分块引擎）‌

#### 七、总结
通过定向优化分块策略，可显著提升RAG系统召回精度，最高降低LLM幻觉率35%

#### 八、开源项目
- Awesome - Chunker
  一站式聚合并复现了当下主流的文本分块技术。包含经典分块方法，如基于字符分割（支持手动设定固定字符长度分割，集成了 LangChain 的 CharacterTextSplitter 和 Llama Index 的 SentenceSplitter）、文档特定分割（针对 Markdown、Python 等不同文档类型有专门策略）、递归字符文本分割（利用 LangChain 的 RecursiveCharacterTextSplitter）。还包括基于 Sentence Transformer 语义分块，通过语义相似度对文本块进行聚类和合并；以及 Dense X Retrieval，以 “命题” 作为新的搜索单元进行分块；LumberChunker 借助大语言模型的理解能力动态分割文档；Meta - Chunking 通过句子之间的困惑度动态调整窗口大小并结合语义理解来实现更精准文本分段。
- Chonkie：为 RAG 任务设计的轻量级文本分块库，以快速性能和易用著称。通过 Tiktoken、预计算缓存等技术实现高效分块，性能远超竞争对手。
- Late Chunking：先进行全面处理再分类整理，利用长上下文 Embedding 模型切分块。文档越长，该策略就越有效，能够保留更多的上下文信息，生成的文本块更加完整和贴切。
- ChunkRAG：显著改进了块级别过滤和细粒度相关性评估，将文本划分为语义上有意义的块，减少了生成不相关或幻觉信息的情况，能生成事实准确且连贯的响应。
- SLM - qwen0.5：包括 simple - qwen - 0.5、topic - qwen - 0.5 和 summary - qwen - 0.5，分别针对不同需求进行分块。simple - qwen - 0.5 基于文档的结构元素识别边界；topic - qwen - 0.5 受到思维链推理的启发，识别文本中的主题来定义分块边界；summary - qwen - 0.5 不仅能识别文本边界，还能为每个文本块生成摘要，适合长文档问答任务。
